{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T19:32:44.756083Z",
     "start_time": "2020-02-21T19:32:44.290601Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rank         Word           Frequency\n",
      "\n",
      "  1            the             20\n",
      "  2            of              10\n",
      "  3            to              10\n",
      "  4            we               7\n",
      "  5            falun            7\n",
      "  6            dafa             6\n",
      "  7            in               5\n",
      "  8            people           5\n",
      "  9            and              4\n",
      " 10            or               4\n",
      " 11            is               4\n",
      " 12            good             4\n",
      " 13            outbreak         3\n",
      " 14            wuhan            3\n",
      " 15            has              3\n",
      " 16            are              3\n",
      " 17            for              3\n",
      " 18            virus            3\n",
      " 19            should           3\n",
      " 20            even             3\n",
      " 21            spread           2\n",
      " 22            other            2\n",
      " 23            world            2\n",
      " 24            chinese          2\n",
      " 25            new              2\n",
      " 26            many             2\n",
      " 27            communist        2\n",
      " 28            regime           2\n",
      " 29            trust            2\n",
      " 30            on               2\n",
      " 31            also             2\n",
      " 32            their            2\n",
      " 33            as               2\n",
      " 34            minghui          2\n",
      " 35            org              2\n",
      " 36            practitioners    2\n",
      " 37            can              2\n",
      " 38            being            2\n",
      " 39            with             2\n",
      " 40            i                2\n",
      " 41            believe          2\n",
      " 42            our              2\n",
      " 43            by               2\n",
      " 44            truthfulness     2\n",
      " 45            compassion       2\n",
      " 46            forbearance      2\n",
      " 47            they             2\n",
      " 48            face             2\n",
      " 49            coronavirus      1\n",
      " 50            china            1\n",
      " 51            its              1\n",
      " 52            quick            1\n",
      " 53            parts            1\n",
      " 54            during           1\n",
      " 55            year             1\n",
      " 56            holiday          1\n",
      " 57            season           1\n",
      " 58            left             1\n",
      " 59            panic            1\n",
      " 60            deep             1\n",
      " 61            frustration      1\n",
      " 62            long             1\n",
      " 63            lost             1\n",
      " 64            public           1\n",
      " 65            cover            1\n",
      " 66            up               1\n",
      " 67            sars             1\n",
      " 68            years            1\n",
      " 69            ago              1\n",
      " 70            criticizing      1\n",
      " 71            officials        1\n",
      " 72            epicenter        1\n",
      " 73            handling         1\n",
      " 74            crisis           1\n",
      " 75            began            1\n",
      " 76            report           1\n",
      " 77            how              1\n",
      " 78            view             1\n",
      " 79            what             1\n",
      " 80            do               1\n",
      " 81            help             1\n",
      " 82            who              1\n",
      " 83            suffering        1\n",
      " 84            facing           1\n",
      " 85            danger           1\n",
      " 86            infected         1\n",
      " 87            increase         1\n",
      " 88            capacity         1\n",
      " 89            show             1\n",
      " 90            more             1\n",
      " 91            empathy          1\n",
      " 92            others           1\n",
      " 93            though           1\n",
      " 94            ourselves        1\n",
      " 95            persecuted       1\n",
      " 96            upholding        1\n",
      " 97            faith            1\n",
      " 98            published        1\n",
      " 99            numerous         1\n",
      "100            stories          1\n",
      "101            about            1\n",
      "102            non              1\n",
      "103            having           1\n",
      "104            health           1\n",
      "105            improved         1\n",
      "106            minds            1\n",
      "107            calmed           1\n",
      "108            dangers          1\n",
      "109            averted          1\n",
      "110            reciting         1\n",
      "111            researchers      1\n",
      "112            around           1\n",
      "113            racing           1\n",
      "114            develop          1\n",
      "115            vaccines         1\n",
      "116            against          1\n",
      "117            novel            1\n",
      "118            deadly           1\n",
      "119            suggest          1\n",
      "120            that             1\n",
      "121            recite           1\n",
      "122            read             1\n",
      "123            zhuan            1\n",
      "124            text             1\n",
      "125            if               1\n",
      "126            truly            1\n",
      "127            healing          1\n",
      "128            power            1\n",
      "129            will             1\n",
      "130            be               1\n",
      "131            able             1\n",
      "132            get              1\n",
      "133            better           1\n",
      "134            avoid            1\n",
      "135            epidemic         1\n",
      "136            all              1\n",
      "137            together         1\n",
      "138            course           1\n",
      "139            order            1\n",
      "140            understand       1\n",
      "141            always           1\n",
      "142            maintain         1\n",
      "143            a                1\n",
      "144            compassionate    1\n",
      "145            heart            1\n",
      "146            talk             1\n",
      "147            them             1\n",
      "148            via              1\n",
      "149            communication    1\n",
      "150            channels         1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>to</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>we</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>falun</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>talk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>them</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>via</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>communication</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>channels</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word  Frequency\n",
       "0              the         20\n",
       "1               of         10\n",
       "2               to         10\n",
       "3               we          7\n",
       "4            falun          7\n",
       "..             ...        ...\n",
       "145           talk          1\n",
       "146           them          1\n",
       "147            via          1\n",
       "148  communication          1\n",
       "149       channels          1\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "\n",
    "resp = requests.get('http://en.minghui.org/html/articles/2020/1/27/182966.html')\n",
    "resp.encoding = 'utf-8'\n",
    "#resp.text\n",
    "soup = BeautifulSoup(resp.text)\n",
    "s = soup.get_text()\n",
    "S = s.split('(Minghui.org)')[-1]                                                              \n",
    "\n",
    " # Isolate the article into a single section.\n",
    "sentence2 = S.split('\\nChinese versoin available')[-1]\n",
    "\n",
    "sentence3 = sentence2.split('Chinese version available')[0]\n",
    "sentence4 = sentence3.replace('\\xa0main', '')\n",
    "\n",
    "#remove any special characters or numbers that would be counted as a word\n",
    "article = sentence4.strip('\\n')\n",
    "\n",
    "article = article.replace(',', ' ').replace('.', ' ').replace('17', ' ').replace('-', ' ').replace('”', ' ').replace('“', ' ').replace('?', ' ')\n",
    "article_final = article.lower().split()\n",
    "\n",
    "#Determine the frequency and rank of each word\n",
    "wordfreq = {}\n",
    "for word in article_final:\n",
    "    if word not in wordfreq:\n",
    "        wordfreq.update({word:1})\n",
    "    else: \n",
    "        x = wordfreq[word]\n",
    "        wordfreq[word] = x + 1\n",
    "\n",
    "\n",
    "#rank the given words and their frequency in descending order\n",
    "\n",
    "rank = 0\n",
    "ranked = sorted(wordfreq.items(), key= lambda x: x[1], reverse=True)\n",
    "#Print the titles\n",
    "print(\" Rank         Word           Frequency\")\n",
    "print('')\n",
    "for freq in ranked:\n",
    "    rank += 1\n",
    "    word = freq[0]\n",
    "    frequency = freq[1]\n",
    "    df = pd.DataFrame(ranked,columns=['Word', 'Frequency'])\n",
    "    \n",
    "    \n",
    "    print('{0:3d} {1:10} {2:15s} {3:2d}'.format(rank, \"\", word, frequency))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-21T19:39:39.171896Z",
     "start_time": "2020-02-21T19:39:39.168855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            1.0         2000  seiuyeqiuty         \n",
      "            1.0            2\n"
     ]
    }
   ],
   "source": [
    "print('{0:15.1f}  {1:11d}  {2:20s}'.format(1.0, 2000, 'seiuyeqiuty'))\n",
    "print('{0:15.1f}  {1:11d}'.format(1.0, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "284px",
    "left": "1029px",
    "right": "20px",
    "top": "208px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
